# ğŸ§  BrainWave AI: Advanced MRI Analysis Platform

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.11+-orange.svg)](https://tensorflow.org)
[![Flask](https://img.shields.io/badge/Flask-2.2+-green.svg)](https://flask.palletsprojects.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

BrainWave AI is a state-of-the-art web application that combines deep learning models for brain MRI analysis, providing both **tumor classification** and **tumor segmentation** capabilities with an intuitive, modern web interface.

> âš ï¸ **Medical Disclaimer**: This tool is for research and educational purposes only. It is not intended for clinical diagnosis or medical decision-making. Always consult qualified healthcare professionals for medical advice.

## ğŸ¯ Key Features

- **ğŸ” Tumor Detection**: Multi-class classification (Glioma, Meningioma, Pituitary, No Tumor)
- **ğŸ¨ Tumor Segmentation**: Precise U-Net based tumor boundary detection
- **ğŸ“± Modern UI**: Glassmorphism design with drag-and-drop functionality
- **ğŸ“Š Scan History**: Persistent storage and visualization of previous analyses
- **âš¡ Real-time Processing**: Instant results with confidence scores
- **ğŸŒ Web-based**: No installation required for end users

## ğŸ—ï¸ Architecture Overview

### Model Pipeline
```
Input MRI Image â†’ Classification Model (VGG16) â†’ Tumor Type + Confidence
                â†“
          Segmentation Model (U-Net) â†’ Tumor Mask + Overlay
```

### Technology Stack
- **Backend**: Flask (Python)
- **Frontend**: HTML5, CSS3, Vanilla JavaScript
- **ML Framework**: TensorFlow/Keras
- **Image Processing**: OpenCV, Pillow (PIL)
- **UI Framework**: Bootstrap 5
- **Styling**: Glassmorphism, CSS Grid/Flexbox

## ğŸ“š Dataset Information

### Primary Dataset: Brain Tumor MRI Dataset
- **Source**: [Kaggle - Brain Tumor MRI Dataset](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)
- **Size**: 7,023 MRI images
- **Classes**: 4 categories
  - **Glioma**: 1,321 images
  - **Meningioma**: 1,339 images  
  - **Pituitary**: 1,457 images
  - **No Tumor**: 2,000 images
- **Format**: JPG images (varying sizes)
- **Split**: 80% Training, 20% Testing

### Segmentation Dataset: LGG MRI Segmentation
- **Source**: [Kaggle - LGG MRI Segmentation](https://www.kaggle.com/datasets/mateuszbuda/lgg-mri-segmentation)
- **Size**: 3,929 brain MRI images
- **Type**: FLAIR (Fluid Attenuated Inversion Recovery) sequences
- **Annotations**: Pixel-level tumor masks
- **Format**: TIFF images with corresponding masks

## ğŸ¤– Model Architecture

### 1. Classification Model (VGG16-based)
```python
# Base Architecture
Input(128, 128, 3) â†’ VGG16(pretrained) â†’ Flatten â†’ Dense(128) â†’ Dense(4)
```

**Training Configuration:**
- Base Model: VGG16 (ImageNet pretrained)
- Fine-tuning: Last 3 layers unfrozen
- Optimizer: Adam (learning rate = 0.0001)
- Loss: Sparse Categorical Crossentropy
- Augmentation: Brightness, Contrast, Rotation
- Epochs: 15
- Batch Size: 20

**Performance Metrics:**
- Training Accuracy: ~94%
- Validation Accuracy: ~91%
- Model Size: ~58MB (.h5 format)

### 2. Segmentation Model (U-Net)
```python
# Architecture
Input(256, 256, 3) â†’ Encoder â†’ Bottleneck â†’ Decoder â†’ Output(256, 256, 1)
```

**Training Configuration:**
- Architecture: Custom U-Net with skip connections
- Optimizer: Adam (learning rate = 0.0001)
- Loss: Dice Coefficient Loss
- Metrics: IoU, Dice Coefficient, Binary Accuracy
- Epochs: 200
- Batch Size: 32

**Performance Metrics:**
- Dice Coefficient: ~0.89
- IoU Score: ~0.84
- Binary Accuracy: ~96%
- Model Size: ~31MB (.keras format)

## ğŸš€ Installation & Setup

### Prerequisites
- Python 3.8 or higher
- 8GB+ RAM recommended
- GPU optional (CPU inference supported)

### Quick Start

#### Windows (PowerShell)
```powershell
# Clone repository
git clone https://github.com/yourusername/brainwave-ai.git
cd brainwave-ai

# Create virtual environment
python -m venv .venv
.\.venv\Scripts\Activate.ps1

# Install dependencies
pip install -r requirements.txt

# Place your trained models in the project root
# - model.h5 (classification model)
# - unet.keras (segmentation model)

# Run application
python main.py
```

The application will be available at `http://localhost:5000`

#### Linux/macOS
```bash
# Clone repository
git clone https://github.com/yourusername/brainwave-ai.git
cd brainwave-ai

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run application
python main.py
```

### Docker Deployment (Optional)
```dockerfile
FROM python:3.9-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY . .
EXPOSE 5000
CMD ["python", "main.py"]
```

**Build and run:**
```bash
docker build -t brainwave-ai .
docker run -p 5000:5000 brainwave-ai
```

## ğŸ“ Project Structure
```
brainwave-ai/
â”œâ”€â”€ main.py                       # Flask application entry point
â”œâ”€â”€ model.h5                      # Trained classification model
â”œâ”€â”€ unet.keras                    # Trained segmentation model
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ scan_history.json            # Scan history storage
â”œâ”€â”€ README.md                     # Documentation
â”œâ”€â”€ LICENSE                       # MIT License
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html               # Main UI template
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Modern styling
â”‚   â”œâ”€â”€ uploads/                 # User uploaded images (generated)
â”‚   â””â”€â”€ results/                 # Generated masks/overlays (generated)
â””â”€â”€ notebooks/
    â”œâ”€â”€ mri_notebook.ipynb       # Classification training notebook
    â””â”€â”€ segmentation.ipynb       # Segmentation training notebook
```

## ğŸ”¬ Model Training Process

### Classification Model Training

The classification model uses transfer learning with VGG16:

**Data Preprocessing:**
- Image augmentation (brightness: 0.8-1.2x, contrast: 0.8-1.2x)
- Normalization to [0, 1] range
- Resize to 128Ã—128 pixels

**Model Architecture:**
```python
base_model = VGG16(weights='imagenet', include_top=False)
# Freeze early layers, fine-tune last 3 blocks
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(4, activation='softmax'))
```

**Training Strategy:**
- Early stopping to prevent overfitting
- Model checkpointing to save best weights
- Learning rate scheduling

### Segmentation Model Training

The U-Net model provides precise tumor boundary detection:

**Data Preprocessing:**
- Resize to 256Ã—256 pixels
- Grayscale to RGB conversion
- Normalization to [0, 1] range
- Binary mask thresholding (threshold = 0.5)

**U-Net Architecture:**
- Encoder: 4 convolutional blocks with max pooling
- Bottleneck: Dense convolutional layer
- Decoder: 4 upsampling blocks with skip connections
- Output: Single channel with sigmoid activation

**Custom Loss Function:**
```python
def dice_coefficient_loss(y_true, y_pred):
    return 1 - dice_coefficient(y_true, y_pred)
```

## ğŸ¨ User Interface Features

### Modern Design Elements
- **Glassmorphism Effects**: Frosted glass appearance with backdrop blur
- **Gradient Backgrounds**: Dynamic color schemes with subtle animations
- **Responsive Design**: Mobile-first approach with adaptive breakpoints
- **Smooth Interactions**: Hover effects and fluid transitions

### Key UI Components

**Upload Interface:**
- Drag-and-drop functionality
- Live image preview
- File type validation (JPEG, PNG)
- Visual feedback and progress indicators

**Results Display:**
- Classification results with confidence percentages
- Side-by-side image comparison (original, mask, overlay)
- Full-screen modal for detailed viewing
- Interactive overlay visualization

**Scan History:**
- JSON-based persistent storage
- Thumbnail grid layout
- Timestamp tracking
- Batch management with clear history option

## ğŸ“Š API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET/POST | Main application interface and image upload |
| `/clear_history` | POST | Clear all scan history |
| `/static/<path>` | GET | Serve static files (CSS, images, results) |

### Response Format
```json
{
  "result": "Tumor: glioma",
  "confidence": "94.56",
  "uploaded_image": "/static/uploads/image_timestamp.jpg",
  "mask_image": "/static/results/mask_timestamp.png",
  "overlay_image": "/static/results/overlay_timestamp.png",
  "scan_history": [...]
}
```

## ğŸ”§ Configuration

### Environment Variables
```bash
FLASK_SECRET_KEY=your-secret-key-here    # Flask session secret
FLASK_ENV=development                     # development or production
PORT=5000                                 # Application port
```

### Model Configuration (main.py)
```python
IMAGE_SIZE_CLASSIFICATION = 128      # Classification input size
IMAGE_SIZE_SEGMENTATION = 256        # Segmentation input size
CONFIDENCE_THRESHOLD = 0.5           # Segmentation threshold
HISTORY_LIMIT = 20                   # Maximum stored scans
```

## ğŸ” Performance Optimization

### Backend Optimizations
- Models loaded once at application startup
- Efficient image processing with PIL/OpenCV
- Proper memory management and cleanup
- Secure filename generation and validation

### Frontend Optimizations
- Hardware-accelerated CSS animations
- Lazy loading for scan history images
- GPU-accelerated transforms
- Responsive image loading

## ğŸ§ª Testing & Validation

### Model Validation Metrics

**Classification:**
- Confusion matrix analysis
- ROC curves and AUC scores
- Per-class precision and recall

**Segmentation:**
- Dice Coefficient: 0.89
- Intersection over Union (IoU): 0.84
- Pixel Accuracy: 96%

### Testing Checklist
- âœ… Upload functionality (drag-drop and click)
- âœ… Model inference pipeline
- âœ… History storage and retrieval
- âœ… Mobile responsiveness
- âœ… Error handling and edge cases
- âœ… Performance under concurrent users

## ğŸš¨ Troubleshooting

### Common Issues

**Model Loading Errors:**
```bash
# Install compatible TensorFlow version
pip install tensorflow==2.11.0
```

**Memory Issues During Inference:**
```python
# Reduce image dimensions or implement batch processing
# Monitor memory usage with system tools
```

**Segmentation Model Format:**
```bash
# Ensure Keras 3+ is installed for .keras format
pip install keras>=3.0
```

**File Upload Failures:**
- Check upload directory permissions
- Verify allowed file extensions in main.py
- Ensure sufficient disk space

## ğŸ”® Future Enhancements

### Planned Features
- 3D volume analysis for MRI sequences
- Multi-modal fusion (T1, T2, FLAIR)
- Tumor volume and growth tracking
- Automated PDF report generation
- User authentication and role management
- Cloud deployment (AWS/Azure/GCP)
- RESTful API with Swagger documentation
- Batch processing for multiple scans

### Model Improvements
- Ensemble methods combining multiple architectures
- Attention mechanisms for improved localization
- Advanced data augmentation strategies
- Domain adaptation techniques
- Uncertainty quantification and confidence intervals

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ“– Citation

If you use this project in your research, please cite:
```bibtex
@software{brainwave_ai_2025,
  title={BrainWave AI: Advanced MRI Analysis Platform},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/brainwave-ai}
}
```

### Dataset Citations

**Brain Tumor Classification Dataset:**
```bibtex
@dataset{nickparvar2021brain,
  title={Brain Tumor MRI Dataset},
  author={Nickparvar, Masoud},
  year={2021},
  publisher={Kaggle},
  url={https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset}
}
```

**LGG Segmentation Dataset:**
```bibtex
@dataset{buda2019lgg,
  title={Association of genomic subtypes of lower-grade gliomas with shape features automatically extracted by a deep learning algorithm},
  author={Buda, Mateusz and Saha, Ashirbani and Mazurowski, Maciej A},
  journal={Computers in Biology and Medicine},
  volume={109},
  year={2019},
  publisher={Elsevier}
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/AmazingFeature`
3. Commit your changes: `git commit -m 'Add some AmazingFeature'`
4. Push to the branch: `git push origin feature/AmazingFeature`
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 style guidelines
- Add comprehensive docstrings
- Include unit tests for new features
- Update documentation for API changes
- Test on multiple platforms before submitting

## ğŸ“§ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/brainwave-ai/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/brainwave-ai/discussions)
- **Email**: your.email@example.com
- **Documentation**: [Project Wiki](https://github.com/yourusername/brainwave-ai/wiki)

## ğŸ™ Acknowledgments

- The Kaggle community for providing high-quality datasets
- TensorFlow and Keras teams for excellent deep learning frameworks
- Flask community for the robust web framework
- All contributors and supporters of this project

---

**Made with â¤ï¸ for advancing medical AI research**
